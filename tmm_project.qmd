---
title: "TMM 기업 분석 프로젝트_MUSINSA"
format: html
code-fold: true
code-tools: true
---

### 분석 기업 / [무신사(MUSINSA)](https://www.musinsa.com/app/)
### 분석 이유
> **무신사**는 국내 최대 온라인 의류 아울렛 플랫폼으로
최근 유명 모델 기용, 대기업과 협업, 오프라인 스토어 런칭 등 공격적 행보를 보이고 있다.
COVID-19 팬데믹 이후 *비대면 온라인 시장*이 활성화 된 시점에서
다른 패션 플랫폼 대비 무신사가 갖는 **차별점**과 앞으로의 **전략**을 분석, 제안하고자 한다.

### 목차
* 자료 수집
    + 빅카인즈 데이터셋 수집
* 자료 분석
    + 총빈도 / 무신사
    + 총빈도 / 패션 플랫폼
* 상대빈도
* 감정 분석
    + 감정 분석 / 무신사
    + 감정 분석 / 패션 플랫폼
* 긍정어 부정어
    + 긍정어 부정어 / 무신사
    + 긍정어 부정어 / 패션 플랫폼
* 토픽모델링
    + 주제별 단어 확률 분포 / 무신사
    + 주제별 단어 확률 분포 / 패션 플랫폼
* 관련 보도 상위 주제어
    + 관련 보도 상위 주제어 / 무신사
    + 관련 보도 상위 주제어 / 패션 플랫폼

### TMM 기업 분석 프로젝트
##### githack HTML / [URL](https://rawcdn.githack.com/Choiiiiis/tmm/fdb396c14c295cbdd333504d65bd9673e0f01b0e/tmm_project.html)

##### 1차 분석(09.21).
데이터셋 500-1000건 대상 빈도분석, 상대빈도, 감정분석, 총빈도 분석.

##### 2차 분석(09.28).
키워드 '무신사'와 '패션 플랫폼 NOT 무신사, cat 서비스-쇼핑'로
전체 패션 플랫폼에서 무신사의 차별점과 전략 분석.

### 자료 수집
##### 빅카인즈 데이터셋 수집
2021.09.27 - 2022.09.27 무신사 2,056건, 패션 플랫폼 1,330건 확보.
```{r}
#| label: data_ready
#| echo: true
#| warning: false

pkg_v <- c("tidyverse", "tidytext", "readxl", "kableExtra", 
           "multilinguer", "RcppMeCab", "KoNLP", "lubridate", 
           "tidylo", "stm", "reshape2", "dplyr", "ggplot2", 
           "stringr", "rvest", "wordcloud")

# 패키지 설치 시 사용
#( pkg_v_installed <- pkg_v %in% installed.packages()[,"Package"] )

#( new_pkg <- pkg_v[!pkg_v_installed] )

#if(length(new_pkg)) install.packages(new_pkg)

lapply(pkg_v, require, ch = T)

musinsa_df <- 
readxl::read_excel("data/NewsResult_20210927-20220927_musinsa.xlsx") %>% 
  select(일자, 제목, 본문, cat = `통합 분류1`) 

plat_df <- 
readxl::read_excel("data/NewsResult_20210927-20220927_plat.xlsx") %>% 
  select(일자, 제목, 본문, cat = `통합 분류1`) 

```


### 자료 분석
##### 총빈도 / 무신사
```{r}
#| label: musinsa_all
#| echo: true
#| warning: false

# "무신사"가 "무신 + 사"로 반영되어 사전에 "무신사" 추가
#buildDictionary(ext_dic = c('sejong', 'woorimalsam'),
#                user_dic = data.frame(term="무신사", tag='ncn'),
#                category_dic_nms=c('brand'))

musinsa2_df <- 
musinsa_df %>% 
  distinct(제목, .keep_all = T) %>% 
  mutate(ID = factor(row_number())) %>% 
  mutate(label = "0") %>%
  unite(제목, 본문, col = "text", sep = " ") %>% 
  mutate(text = str_squish(text))

musinsa_tk <- musinsa2_df %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = extractNoun, drop = F) %>%
#  separate(word, c("word", "pos"), sep = "/") %>% 
#  filter(pos == "nng") %>% 
  count(word, sort = T)

musinsa_tk <- 
musinsa_tk %>% 
  filter(!word %in% c("무신사", "MUSINSA", "기자")) %>% 
  filter(str_detect(word, "[:alpha:]+"))

musinsa_tk %>%
  filter(str_length(word) > 1) %>%
  slice_max(n, n = 15) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip() +
  labs(title = "무신사 총빈도")

```


##### 총빈도 / 패션 플랫폼
```{r}
#| label: plat_all
#| echo: true
#| warning: false

plat2_df <- 
plat_df %>% 
  distinct(제목, .keep_all = T) %>% 
  mutate(ID = factor(row_number())) %>% 
  mutate(label = "1") %>%
  unite(제목, 본문, col = "text", sep = " ") %>% 
  mutate(text = str_squish(text))

plat_tk <- plat2_df %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = extractNoun, drop = F) %>%
  count(word, sort = T)

plat_tk <- 
plat_tk %>% 
  filter(!word %in% c("기자", "패션", "플랫폼")) %>% 
  filter(str_detect(word, "[:alpha:]+"))

plat_tk %>%
  filter(str_length(word) > 1) %>%
  slice_max(n, n = 15) %>% 
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip() +
    labs(title = "패션 플랫폼 총빈도")
```


### 상대빈도
```{r}
#| label: vs
#| echo: true
#| warning: false

vs_df <- rbind(musinsa2_df, plat2_df)

set.seed(25)

vsvs_df <- 
  vs_df[-c(1, 3)] %>% 
  relocate(c(ID, text)) %>%
  group_by(label) %>% 
  sample_n(size = 1300)

rate_odds_df <- 
vsvs_df %>% 
  unnest_tokens(word, text, token = pos) %>% 
  separate(word, c("word", "pos"), sep = "/") %>% 
  filter(pos == "nng") %>% 
  count(word) %>% 
  pivot_wider(names_from = label,
              values_from = n, 
              values_fill = list(n = 0)) %>% 
  rename(posi = `1`, nega = `0`) %>% 
  mutate(odds_posi = ((posi+1)/sum(posi+1)),
         odds_nega = ((nega+1)/sum(nega+1))) %>% 
  mutate(posi_odds_ratio = (odds_posi / odds_nega)) %>% 
  filter(rank(posi_odds_ratio) <= 20 | rank(-posi_odds_ratio) <= 20) %>%   arrange(-posi_odds_ratio)

rate_log_df <- 
vsvs_df %>% 
  unnest_tokens(word, text, token = pos) %>% 
  separate(word, c("word", "pos"), sep = "/") %>% 
  filter(pos == "nng") %>% 
  count(word) %>% 
  pivot_wider(names_from = label,
              values_from = n, 
              values_fill = list(n = 0)) %>% 
  rename(posi = `1`, nega = `0`) %>% 
  mutate(odds_posi = ((posi+1)/sum(posi+1)),
         odds_nega = ((nega+1)/sum(nega+1))) %>% 
  mutate(log_odds_ratio = log(odds_posi / odds_nega)) 

weighted_log_odds_df <- 
vsvs_df %>% 
  unnest_tokens(word, text, token = pos) %>% 
  separate(word, c("word", "pos"), sep = "/") %>% 
  filter(pos == "nng") %>% 
  filter(str_length(word) > 1) %>%
  filter(word != "무신") %>% 
  filter(word != "신사") %>% 
  filter(word != "패션") %>% 
  filter(word != "플랫폼") %>% 
  filter(word != "기자") %>% 
  count(word) %>% 
  bind_log_odds(set = label,
                feature = word,
                n = n) %>% 
  arrange(-log_odds_weighted)

weighted_log_odds_df %>%
  group_by(label = ifelse(label > 0, "패션 플랫폼", "무신사")) %>%
  slice_max(abs(log_odds_weighted), n = 10) %>%
  ggplot(aes(x = log_odds_weighted,
             y = reorder(word, log_odds_weighted),
             fill = label)) +
  geom_col(show.legend = F) +
  facet_wrap(~label, scale = "free")

```


### 감정 분석
##### 감정 분석 / 무신사
```{r}
#| label: musinsa_senti
#| echo: true
#| warning: false

# "knusenti" 설치 코드
#url_v <- "https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip"

#dest_v <- "data/knusenti.zip"

#download.file(url = url_v, 
#              destfile = dest_v,
#              mode = "wb")

#unzip("knusenti.zip", exdir = "data")

senti_name_v <- list.files("data/KnuSentiLex-master/.")[9]

senti_dic_df <- read_tsv(str_c("data/KnuSentiLex-master/", senti_name_v), col_names = F)

senti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)

knu_dic_df <- senti_dic_df %>% 
  filter(!is.na(sScore))

musinsa_senti_df <- musinsa2_df %>% 
  unnest_tokens(word, text, token = extractNoun) %>% 
  inner_join(knu_dic_df) %>% 
  count(word, sScore, sort = T) %>% 
  filter(str_length(word) > 1) %>% 
  filter(!word %in% c("대상")) %>% 
  mutate(word = reorder(word, n)) %>% 
  slice_head(n = 20)

musinsa_senti_df %>% 
  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +
    labs(title = "무신사 감정빈도 분석")

```


##### 감정 분석 / 패션 플랫폼
```{r}
#| label: plat_senti
#| echo: true
#| warning: false

plat_senti_df <- plat2_df %>% 
  unnest_tokens(word, text, token = extractNoun) %>% 
  inner_join(knu_dic_df) %>% 
  count(word, sScore, sort = T) %>% 
  filter(str_length(word) > 1) %>% 
  filter(!word %in% c("대상")) %>% 
  mutate(word = reorder(word, n)) %>% 
  slice_head(n = 20)

plat_senti_df %>% 
  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +
    labs(title = "패션 플랫폼 감정빈도 분석",)

```


### 긍정어 부정어
##### 긍정어 부정어 / 무신사
```{r}
#| label: musinsa_pone
#| echo: true
#| warning: false

musinsa2_df %>% 
  unnest_tokens(word, text) %>% 
  left_join(knu_dic_df) %>% 
  mutate(sScore = ifelse(sScore >= 1, "긍정",
                         ifelse(sScore <= -1, "부정", "중립"))) %>% 
  count(sScore)

# 워드클라우드
musinsa2_df %>% 
  unnest_tokens(word, text) %>% 
  inner_join(knu_dic_df) %>% 
  mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>% 
  filter(emotion != "중립") %>% 
  count(word, emotion, sort = T) %>% 
  filter(str_length(word) > 1) %>% 
  filter(!word %in% c("대상")) %>% 
  reshape2::acast(word ~ emotion, value.var = "n", fill = 0) %>% 
  comparison.cloud(colors = c("blue", "red"), max.words = 50)

musinsa2_df %>%   
  unnest_tokens(word, text, token = extractNoun) %>% 
  inner_join(knu_dic_df) %>% 
  mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%
  mutate(label = ifelse(sScore > 0, "1", ifelse(sScore < 0, "0", "2"))) %>%
  filter(label != "중립") %>%
  count(word, emotion, label, sort = T) %>%
  filter(str_length(word) > 1) %>%
  filter(!word %in% c("대상")) %>% 
  group_by(label = ifelse(label > 0, "긍정", "부정")) %>%
  slice_head(n = 15) %>%
  ggplot(aes(x = n,
             y = reorder(word, n), fill = label)) +
  geom_col(show.legend = F) +
  facet_wrap(~label, scale = "free") +
  labs(title = "무신사 긍정어 부정어")

```


##### 긍정어 부정어 / 패션 플랫폼
```{r}
#| label: plat_pone
#| echo: true
#| warning: false

plat2_df %>% 
  unnest_tokens(word, text) %>% 
  left_join(knu_dic_df) %>% 
  mutate(sScore = ifelse(sScore >= 1, "긍정",
                         ifelse(sScore <= -1, "부정", "중립"))) %>% 
  count(sScore)

# 워드클라우드
plat2_df %>% 
  unnest_tokens(word, text) %>% 
  inner_join(knu_dic_df) %>% 
  mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>% 
  filter(emotion != "중립") %>% 
  count(word, emotion, sort = T) %>% 
  filter(str_length(word) > 1) %>% 
  filter(!word %in% c("대상")) %>% 
  reshape2::acast(word ~ emotion, value.var = "n", fill = 0) %>% 
  comparison.cloud(colors = c("blue", "red"), max.words = 50)

plat2_df %>%   
  unnest_tokens(word, text, token = extractNoun) %>% 
  inner_join(knu_dic_df) %>% 
  mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%
  mutate(label = ifelse(sScore > 0, "1", ifelse(sScore < 0, "0", "2"))) %>%
  filter(label != "중립") %>% 
  count(word, emotion, label, sort = T) %>%
  filter(str_length(word) > 1) %>%
  filter(!word %in% c("대상")) %>% 
  group_by(label = ifelse(label > 0, "긍정", "부정")) %>%
  slice_head(n = 15) %>%
  ggplot(aes(x = n,
             y = reorder(word, n), fill = label)) +
  geom_col(show.legend = F) +
  facet_wrap(~label, scale = "free") +
  labs(title = "패션 플랫폼 긍정어 부정어")

```


### 토픽모델링
##### 주제별 단어 확률 분포 / 무신사
```{r}
#| label: musinsa_topic
#| echo: true
#| warning: false

musinsa_topic_tk <- musinsa2_df %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = extractNoun, drop = F)

musinsa_topic_tk <- 
musinsa_topic_tk %>% 
  filter(!word %in% c("무신사", "MUSINSA", "기자", "대상")) %>% 
  filter(str_detect(word, "[:alpha:]+"))

musinsa_combined_df <-
  musinsa_topic_tk %>%
  group_by(ID) %>%
  summarise(text2 = str_flatten(word, " ")) %>%
  ungroup() %>% 
  inner_join(musinsa2_df, by = "ID")

processed <- 
  musinsa2_df %>% textProcessor(
    documents = musinsa_combined_df$text2,
    metadata = .,
    wordLengths = c(2, Inf)
    )

out <-
  prepDocuments(processed$documents,
                processed$vocab,
                processed$meta, 
                lower.thresh = 0)

docs <- out$documents
vocab <- out$vocab
meta <- out$meta

topicN <- c(3, 10)

storage <- searchK(out$documents, out$vocab, K = topicN)

musinsa_stm_fit <-
  stm(
    documents = docs,
    vocab = vocab,
    K = 6,
    data = meta,
    max.em.its = 75,
    init.type = "Spectral",
    seed = 25,
    verbose = F
  )

musinsa_td_beta <- musinsa_stm_fit %>% tidy(matrix = 'beta') 

musinsa_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 7) %>% 
  ungroup() %>% 
  mutate(topic = str_c("주제", topic)) %>% 
  ggplot(aes(x = beta, 
             y = reorder(term, beta),
             fill = topic)) +
  geom_col(show.legend = F) +
  facet_wrap(~topic, scales = "free") +
  labs(x = expression("단어 확률분포: "~beta), y = NULL,
       title = "주제별 단어 확률 분포",
       subtitle = "각 주제별로 다른 단어들로 군집") +
  theme(plot.title = element_text(size = 20))


```


##### 주제별 단어 확률 분포 / 패션 플랫폼
```{r}
#| label: plat_topic
#| echo: true
#| warning: false

plat_topic_tk <- plat2_df %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = extractNoun, drop = F)

plat_topic_tk <- 
plat_topic_tk %>% 
  filter(!word %in% c("기자", "패션", "플랫폼", "대상")) %>% 
  filter(str_detect(word, "[:alpha:]+"))

plat_combined_df <-
  plat_topic_tk %>%
  group_by(ID) %>%
  summarise(text2 = str_flatten(word, " ")) %>%
  ungroup() %>% 
  inner_join(plat2_df, by = "ID")

processed <- 
  plat2_df %>% textProcessor(
    documents = plat_combined_df$text2,
    metadata = .,
    wordLengths = c(2, Inf))

out <-
  prepDocuments(processed$documents,
                processed$vocab,
                processed$meta, 
                lower.thresh = 0)

docs <- out$documents
vocab <- out$vocab
meta <- out$meta

topicN <- c(3, 10)

#storage <- searchK(out$documents, out$vocab, K = topicN)

plat_stm_fit <-
  stm(
    documents = docs,
    vocab = vocab,
    K = 6,
    data = meta,
    max.em.its = 75,
    init.type = "Spectral",
    seed = 25,
    verbose = F
  )

plat_td_beta <- plat_stm_fit %>% tidy(matrix = 'beta') 

plat_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 7) %>% 
  ungroup() %>% 
  mutate(topic = str_c("주제", topic)) %>%
  ggplot(aes(x = beta, 
             y = reorder(term, beta),
             fill = topic)) +
  geom_col(show.legend = F) +
  facet_wrap(~topic, scales = "free") +
  labs(x = expression("단어 확률분포: "~beta), y = NULL,
       title = "주제별 단어 확률 분포",
       subtitle = "각 주제별로 다른 단어들로 군집") +
  theme(plot.title = element_text(size = 20))

```


### 관련 보도 상위 주제어
##### 관련 보도 상위 주제어 / 무신사
```{r}
#| label: musinsa_word
#| echo: true
#| warning: false

musinsa_td_gamma <- musinsa_stm_fit %>% tidy(matrix = "gamma") 

musinsa_top_terms <- 
musinsa_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 5) %>% 
  select(topic, term) %>% 
  summarise(terms = str_flatten(term, collapse = ", ")) 

musinsa_gamma_terms <- 
musinsa_td_gamma %>% 
  group_by(topic) %>% 
  summarise(gamma = mean(gamma)) %>% 
  left_join(musinsa_top_terms, by = 'topic') %>% 
  mutate(topic = str_c("주제", topic),
         topic = reorder(topic, gamma))

musinsa_gamma_terms %>% 
  ggplot(aes(x = gamma, y = topic, fill = topic)) +
  geom_col(show.legend = F) +
  geom_text(aes(label = round(gamma, 2)),
            hjust = 1.4) +
  geom_text(aes(label = terms), 
            hjust = -0.05) +
  scale_x_continuous(expand = c(0, 0),
                     limit = c(0, 1)) +
  labs(x = expression("문서 확률분포"~(gamma)), y = NULL,
       title = "무신사 관련 보도 상위 주제어",
       subtitle = "주제별로 기여도가 높은 단어 중심") +
  theme(plot.title = element_text(size = 20))
```


##### 관련 보도 상위 주제어 / 패션 플랫폼
```{r}
#| label: plat_word
#| echo: true
#| warning: false

plat_td_gamma <- plat_stm_fit %>% tidy(matrix = "gamma") 

plat_top_terms <- 
plat_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 5) %>% 
  select(topic, term) %>% 
  summarise(terms = str_flatten(term, collapse = ", ")) 

plat_gamma_terms <- 
plat_td_gamma %>% 
  group_by(topic) %>% 
  summarise(gamma = mean(gamma)) %>% 
  left_join(plat_top_terms, by = 'topic') %>% 
  mutate(topic = str_c("주제", topic),
         topic = reorder(topic, gamma))

plat_gamma_terms %>% 
  ggplot(aes(x = gamma, y = topic, fill = topic)) +
  geom_col(show.legend = F) +
  geom_text(aes(label = round(gamma, 2)),
            hjust = 1.4) +
  geom_text(aes(label = terms), 
            hjust = -0.05) +
  scale_x_continuous(expand = c(0, 0),
                     limit = c(0, 1)) +
  labs(x = expression("문서 확률분포"~(gamma)), y = NULL,
       title = "패션 플랫폼 관련 보도 상위 주제어",
       subtitle = "주제별로 기여도가 높은 단어 중심") +
  theme(plot.title = element_text(size = 20))
```

